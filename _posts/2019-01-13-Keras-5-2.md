---
title : \[Keras Study\] 5장. 컴퓨터 비전을 위한 딥러닝 (2)
category :
  - ML
tag :
  - keras
  - deep-learning
  - AI
  - machine learning
  - colab
sidebar:
  nav: sidebar-keras

use_math : true
header:
  teaser : /assets/images/category/ml.jpg
  overlay_image : /assets/images/category/ml.jpg

published : false
---

실전 딥러닝! 딥러닝을 이용한 예제를 풀어봅시다.

본 문서는 [케라스 창시자에게 배우는 딥러닝] 책을 기반으로 하고 있으며, subinium(본인)이 정리하고 추가한 내용입니다. 생략된 부분과 추가된 부분이 있으니 추가/수정하면 좋을 것 같은 부분은 댓글로 이야기해주시면 감사하겠습니다.

- 책에서는 일부 부분에서 width를 넓이라고 번역합니다. 매우 불편하니 너비로 수정하여 정리하겠습니다.

## 5.3 사전 훈련된 컨브넷 사용하기

작은 이미지 데이터 셋에서 딥러닝을 적용하는 일반적이고 매우 효과적인 방법은 사전 훈련된 네트워크를 사용하는 것입니다.
**사전 훈련된 네트워크(pretrained network)** 는 일반적으로 대규모 이미지 분류 문제를 위해 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크입니다.

즉 ImageNet와 같이 큰 데이터셋에서 훈련된 대규모 컨브넷을 사용하면 지금 문제에도 좋은 성능을 낼 것입니다.
여러 모델이 있지만 여기서는 VGG16 모델을 사용합니다.

사전 훈련된 네트워크는 2가지 방법으로 사용할 수 있습니다.

1. 특성 추출(feature extraction)
2. 미세 조정(fine tuning)

### 5.3.1 특성 추출

**특성 추출** 은 사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서 흥미로운 특성을 뽑아 내는 것입니다.
이런 특성을 사용하여 새로운 분류기를 처음부터 훈련합니다.

컨브넷은 이미지 분류를 위해 두 부분으로 구성됩니다.

- 합성곱 기반 층 : 합성곱과 풀링 층으로 구성
- 완전 연결 분류기

컨브넷의 경우 특성 추출은 사전에 훈련된 네트워크의 합성곱 기반 층을 선택하여 새로운 데이터를 통과시키고, 그 출력으로 새로운 분류기를 훈련합니다.

완전 연결 분류기 재사용은 권장하지 않고 있습니다. 합성곱 층에 학습된 표현이 더 일반적이어서 재사용이 가능하기 때문입니다.
그 이유는 다음과 같습니다.

- 컨브넷의 특성 맵은 사진에 대한 일반적인 콘셉트의 존재 여부를 기록한 맵입니다.
- 분류기는 전체 사진에 어떤 클래스가 존재할 확률 정보 -> 훈련된 클래스 집합에 특화
- 완전 연결 층에서 찾은 표현은 더 이상 입력 이미지에 있는 위치 정보를 가지고 있지 않음 -> 객체 위치가 중요한 문제라면 더욱 필요없음

특정 합성곱 층에서 추출한 표현의 일반성 및 재사용성 수준은 모델에 있는 층의 깊이에 따라 달려있습니다.

- 하위 층 : 에지, 색깔, 질감 등 지역적이고 매우 일반적인 특성 맵
- 상위 층 : 강아지 눈, 고양이 귀와 같은 좀 더 추상적인 개념

새로운 데이터셋과 훈련된 데이터셋이 많이 다르다면 전체 합성곱 기반 층이 아닌 모델의 하위 층 몇 개만 특성 추출에 사용하는 것이 좋습니다.

ImageNet 클래스에서는 강아지와 고양이가 있기 때문에 완전 연결 층 정보를 재사용해도 좋지만 일반적인 케이스를 위해 여기서는 사용하지 않습니다. ImageNet 데이터셋에서 훈련된 VCG16 네트워크에서 유용한 특성을 추출합니다. 그 후 특성으로 훈련을 진행합니다.

VGG16 모델은 케라스 패키지로 존재하며 `keras.applications` 모듈에서 import 할 수 있습니다.
이 모듈에서 사용가는한 이미지 분류 모델은 다음과 같습니다.

- Xception
- Inception V3
- ResNet50
- VGG16
- VGG19
- MobileNet

모델은 다음과 같이 만들 수 있습니다.

``` python
# 코드 5-16 VGG16 합성곱 기반 층 만들기
from keras.applications import VGG16

conv_base = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(150, 150, 3))
```

VGG16 함수에서는 3개의 매개변수를 전달합니다.

- `weights`는 모델을 초기화할 가중치 체크포인트를 지정합니다.
- `include_top`은 네트워크의 최상위 완전 연결 분류기를 포함할지 안할지를 지정합니다. 기본값은 ImageNet의 1,000개의 클래스에 대응되는 완전 연결 분류기를 포함합니다. 별도의 (강아지와 고양이 두 개의 클래스를 구분하는) 완전 연결 층을 추가하려고 하므로 이를 포함시키지 않습니다.
- `input_shape`은 네트워크에 주입할 이미지 텐서의 크기입니다. 이 매개변수는 선택사항입니다. 이 값을 지정하지 않으면 네트워크가 어떤 크기의 입력도 처리할 수 있습니다.

최종 특성 맵의 크기는 (4, 4, 512) 입니다. 여기에서 완전 연결 층은 2가지 방식으로 놓을 수 있습니다.

- 새로운 데이터셋에서 합성곱 기반 층을 실행하고 출력을 넘파이 배열로 디스크에 저장합니다. 그다음 이 데이터를 독립된 완전 연결 분류기에 입력으로 사용합니다. 이 방식에서는 합성곱 기반 층을 한 번만 실행하기 때문에 빠르고 비용이 적게 듭니다. 하지만 데이터 증식을 사용할 수 없습니다.
- 준비한 모델(conv_base)에 Dense 층을 쌓아 확장합니다. 그리고 입력 데이터에서 엔드-투-엔드로 전체 모델을 실행합니다. 모델에 노출된 모든 입력 이미지가 매번 합성곱 기반 층을 통과하므로 데이터 증식을 사용할 수 있습니다. 하지만 첫 번째 방식보다 훨씬 비용이 많이 듭니다.

각각의 방법으로 구현은 다음과 같이 할 수 있습니다.

#### 데이터 증식을 사용하지 않는 빠른 특성 추출

#### 데이터 증식을 사용한 특성 추출


### 5.3.2 미세 조정

### 5.3.3 정리

## 5.4 컨브넷 학습 시각화

### 5.4.1 중간층의 활성화 시각화하기

### 5.4.2 컨브넷 필터 시각화하기

### 5.4.3 클래스 활성화의 히트맵 시각화하기

## 5.5 요약
